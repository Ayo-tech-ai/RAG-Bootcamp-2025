{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsk-ai/RAG-Bootcamp-2025/blob/main/Hybrid_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ewhNc58Ef3x"
      },
      "source": [
        "## Hybrid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_nd4l72bU8ud",
        "outputId": "a8f3361b-5298-4416-ebee-fbfa532f33f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zTs_8JUQYso8",
        "outputId": "16f204c4-c4d4-41e9-be08-e39ab1075924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb5869F-b-ty"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Access the secret using userdata.get()\n",
        "my_variable = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "# You can also set it as an environment variable for use with os.getenv()\n",
        "os.environ['GROQ_API_KEY'] = my_variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MiNNNjSeV0RI",
        "outputId": "657c8bda-ae05-4d68-b158-82149c292d4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -qU langchain-community chromadb faiss-cpu sentence-transformers rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "7aace2c120e3406092d5c7d176db7f94",
            "0a4631a47c61490abb024dd7ac38ddad",
            "2cd3e65c457041bb9ccc092995483b1d",
            "5cfc4ccab304428188f90b8112665174",
            "482b218a54544f529131bd9e0e55f1a8",
            "08f647bcb98d4c6780011af3dbdca264",
            "448461d821104d028c95a6c04d36d3ec",
            "f32d712c80204ef8b1a76748006a07f9",
            "d15ed7c55f29457cac0a2fea4efb175f",
            "1af5483a5694439597af97aa2f31952c",
            "6086914ab22445279099621ea545c3a6"
          ]
        },
        "collapsed": true,
        "id": "hMgYXkDWbxHk",
        "outputId": "5ca375be-a6af-4ce5-a00e-d54a5cd8778e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1615939869.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7aace2c120e3406092d5c7d176db7f94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a4631a47c61490abb024dd7ac38ddad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cd3e65c457041bb9ccc092995483b1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cfc4ccab304428188f90b8112665174",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "482b218a54544f529131bd9e0e55f1a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08f647bcb98d4c6780011af3dbdca264",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "448461d821104d028c95a6c04d36d3ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f32d712c80204ef8b1a76748006a07f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d15ed7c55f29457cac0a2fea4efb175f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1af5483a5694439597af97aa2f31952c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6086914ab22445279099621ea545c3a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# 1. Initialize our Embedding Model\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NPrlQqct5NN"
      },
      "outputs": [],
      "source": [
        "# Create some dummy documents to highlight the benefits of hybrid search.\n",
        "# Notice the mix of keyword-heavy and concept-heavy text.\n",
        "texts = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A fast, agile fox leaps over a lethargic canine.\",\n",
        "    \"The product code for the new widget is WGT-7890. It has an amazing feature set.\",\n",
        "    \"Our latest financial report for Q2 2024 shows significant growth in the technology sector.\",\n",
        "    \"Financial results for the second quarter of 2024 indicate robust performance.\",\n",
        "    \"The concept of quantum entanglement is fascinating, where particles become linked.\",\n",
        "    \"Resetting your password is easy. Navigate to the account settings and click 'Forgot Password'.\",\n",
        "    \"How do I change my PIN? You can modify your Personal Identification Number in the security section of your profile.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrRcOvsMxroP"
      },
      "outputs": [],
      "source": [
        "documents = [Document(page_content=t, metadata={\"source\": f\"doc_{i}\"}) for i, t in enumerate(texts)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvaii1RUxy_e",
        "outputId": "36ccff57-ae03-46a3-c63d-c117dd959409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chunks prepared: 8\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Prepare chunks (from Document Loading and Chunking) ---\n",
        "# In a real app, this would come after loading documents. For this example, our texts are already small.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"Total chunks prepared: {len(chunks)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFpLtibyykqt",
        "outputId": "e7f9743f-4343-4a5b-8036-723f1d75fe14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dense (VectorStore) Retriever created.\n"
          ]
        }
      ],
      "source": [
        "# --- 2. Create a Vector Store (ChromaDB) for Dense Search ---\n",
        "# Using in-memory Chroma for simplicity. In a real project, you'd persist this.\n",
        "vectorstore = Chroma.from_documents(chunks, embeddings_model)\n",
        "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "print(\"\\nDense (VectorStore) Retriever created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT6IeShM8rb1",
        "outputId": "2cce6821-d763-400d-bf70-15819fc30a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparse (BM25) Retriever created.\n"
          ]
        }
      ],
      "source": [
        "# --- 3. Create a BM25 Retriever for Sparse Search ---\n",
        "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
        "bm25_retriever.k = 5\n",
        "print(\"Sparse (BM25) Retriever created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ODgglDw-k3u"
      },
      "source": [
        "### Example 1: Basic Hybrid Search with Equal Weights\n",
        "\n",
        "This is the most common starting point. We give equal importance to both sparse and dense search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8G-Ws-A-liH",
        "outputId": "ced6183a-352f-41dc-8a27-4b19d76084e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Example 1: Basic Hybrid Search (Equal Weights) ---\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Example 1: Basic Hybrid Search (Equal Weights) ---\")\n",
        "# Initialize the EnsembleRetriever\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, vector_retriever],\n",
        "    weights=[0.5, 0.5] # 50/50 weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk8aTUJ2--YQ",
        "outputId": "2e8588dc-555b-4be6-ba8b-57ae8d8ae4c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 'info on product WGT-7890'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# A query with a strong keyword but also a conceptual part\n",
        "query_hybrid_1 = \"info on product WGT-7890\"\n",
        "print(f\"Query: '{query_hybrid_1}'\")\n",
        "retrieved_docs_hybrid_1 = ensemble_retriever.invoke(query_hybrid_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0nvRM77_M2i",
        "outputId": "3c4deaaa-f926-41aa-dd53-e3e8a47bca01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Retrieved 6 documents with Hybrid Search:\n",
            "  1. Source: doc_2, Content: 'The product code for the new widget is WGT-7890. It has an amazing feature set.'\n",
            "  2. Source: doc_7, Content: 'How do I change my PIN? You can modify your Personal Identification Number in the security section of your profile.'\n",
            "  3. Source: doc_5, Content: 'The concept of quantum entanglement is fascinating, where particles become linked.'\n",
            "  4. Source: doc_4, Content: 'Financial results for the second quarter of 2024 indicate robust performance.'\n",
            "  5. Source: doc_3, Content: 'Our latest financial report for Q2 2024 shows significant growth in the technology sector.'\n",
            "  6. Source: doc_6, Content: 'Resetting your password is easy. Navigate to the account settings and click 'Forgot Password'.'\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nRetrieved {len(retrieved_docs_hybrid_1)} documents with Hybrid Search:\")\n",
        "for i, doc in enumerate(retrieved_docs_hybrid_1):\n",
        "    print(f\"  {i+1}. Source: {doc.metadata.get('source', 'N/A')}, Content: '{doc.page_content}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWV4j1ki_POU",
        "outputId": "ca3f68f2-e5b0-45b5-acfe-084f8e346ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Individual Retriever Comparison for the Same Query ---\n",
            "BM25 Results (strong on keywords):\n",
            "  1. Source: doc_2, Content: 'The product code for the new widget is WGT-7890. It has an amazing feature set.'\n",
            "  2. Source: doc_7, Content: 'How do I change my PIN? You can modify your Personal Identification Number in the security section of your profile.'\n",
            "  3. Source: doc_5, Content: 'The concept of quantum entanglement is fascinating, where particles become linked.'\n"
          ]
        }
      ],
      "source": [
        "# Now, let's compare this to what each retriever would have found on its own.\n",
        "# This is crucial for understanding WHY hybrid is better.\n",
        "print(\"\\n--- Individual Retriever Comparison for the Same Query ---\")\n",
        "print(\"BM25 Results (strong on keywords):\")\n",
        "bm25_results_1 = bm25_retriever.invoke(query_hybrid_1)\n",
        "for i, doc in enumerate(bm25_results_1[:3]): # Show top 3\n",
        "    print(f\"  {i+1}. Source: {doc.metadata.get('source', 'N/A')}, Content: '{doc.page_content}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj6Qyn8m_cZ_",
        "outputId": "457cc497-5b61-428e-89b9-642504bad956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "VectorStore Results (might miss the specific code):\n",
            "  1. Source: doc_2, Content: 'The product code for the new widget is WGT-7890. It has an amazing feature set.'\n",
            "  2. Source: doc_3, Content: 'Our latest financial report for Q2 2024 shows significant growth in the technology sector.'\n",
            "  3. Source: doc_4, Content: 'Financial results for the second quarter of 2024 indicate robust performance.'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nVectorStore Results (might miss the specific code):\")\n",
        "vector_results_1 = vector_retriever.invoke(query_hybrid_1)\n",
        "for i, doc in enumerate(vector_results_1[:3]): # Show top 3\n",
        "    print(f\"  {i+1}. Source: {doc.metadata.get('source', 'N/A')}, Content: '{doc.page_content}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmvXGVE7gOLT"
      },
      "source": [
        "### Example 2: Hybrid Search with Weighted Preference\n",
        "\n",
        "What if we know our users primarily ask conceptual questions, but we still want keyword search as a safety net? We can adjust the weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckRWh5pnE523",
        "outputId": "ee236bee-8f0e-410a-eac3-e856dafa1336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Example 2: Hybrid Search (Preferring Dense Search) ---\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Example 2: Hybrid Search (Preferring Dense Search) ---\")\n",
        "# Let's say we generally prefer semantic results, but still want keyword backup.\n",
        "ensemble_retriever_biased = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, vector_retriever],\n",
        "    weights=[0.3, 0.7] # 30% BM25, 70% VectorStore\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpqgvEyrE81c",
        "outputId": "9d00f49b-91e5-48b0-8900-ffe59b8bbdd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 'how can I change my personal identification number?'\n",
            "\n",
            "Retrieved 6 documents with Biased Hybrid Search:\n",
            "  1. Source: doc_7, Content: 'How do I change my PIN? You can modify your Personal Identification Number in the security section of your profile.'\n",
            "  2. Source: doc_6, Content: 'Resetting your password is easy. Navigate to the account settings and click 'Forgot Password'.'\n",
            "  3. Source: doc_5, Content: 'The concept of quantum entanglement is fascinating, where particles become linked.'\n",
            "  4. Source: doc_3, Content: 'Our latest financial report for Q2 2024 shows significant growth in the technology sector.'\n",
            "  5. Source: doc_2, Content: 'The product code for the new widget is WGT-7890. It has an amazing feature set.'\n",
            "  6. Source: doc_4, Content: 'Financial results for the second quarter of 2024 indicate robust performance.'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# A query that is strongly semantic\n",
        "query_hybrid_2 = \"how can I change my personal identification number?\"\n",
        "print(f\"Query: '{query_hybrid_2}'\")\n",
        "retrieved_docs_hybrid_2 = ensemble_retriever_biased.invoke(query_hybrid_2)\n",
        "\n",
        "print(f\"\\nRetrieved {len(retrieved_docs_hybrid_2)} documents with Biased Hybrid Search:\")\n",
        "for i, doc in enumerate(retrieved_docs_hybrid_2):\n",
        "    print(f\"  {i+1}. Source: {doc.metadata.get('source', 'N/A')}, Content: '{doc.page_content}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9rPQOZnFCI2"
      },
      "outputs": [],
      "source": [
        "# Example with a numerical filter (year must be 2024)\n",
        "# Note: ChromaDB supports operators like $eq, $ne, $gt, $gte, $lt, $lte\n",
        "recent_report_retriever = db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 2, \"filter\": {\"year\": {\"$eq\": 2024}}}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hfKjJMOFMAf",
        "outputId": "a5fbae8a-f2cb-49de-cd83-13c63f8d0c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Filtered Dense Search for: 'What are the latest developments?' (Year = 2024) ---\n",
            "Doc 1: Content='Our quarterly report shows a 15% growth in the tech sector, largely driven by AI advancements.'\n",
            "   Source='financial-report', Year='2024'\n",
            "\n",
            "Doc 2: Content='The new CEO, Sarah Jenkins, announced a company-wide focus on AI integration.'\n",
            "   Source='press-release', Year='2024'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "query_numerical = \"What are the latest developments?\"\n",
        "retrieved_num_filtered = recent_report_retriever.invoke(query_numerical)\n",
        "print(f\"\\n--- Filtered Dense Search for: '{query_numerical}' (Year = 2024) ---\")\n",
        "for i, doc in enumerate(retrieved_num_filtered):\n",
        "    print(f\"Doc {i+1}: Content='{doc.page_content}'\")\n",
        "    print(f\"   Source='{doc.metadata.get('source')}', Year='{doc.metadata.get('year')}'\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk3CWHiwFj8Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4g2IeNbCkse9SCrT7yY9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}