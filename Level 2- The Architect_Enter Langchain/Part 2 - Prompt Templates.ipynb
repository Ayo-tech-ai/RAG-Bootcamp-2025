{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d3d7214-89d5-4cf0-b760-ae5043268c3b",
   "metadata": {},
   "source": [
    "# Part 2: Prompts Template & Messages — Speaking the Language of LLMs with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d05024-ed60-4ecf-82a3-6bb36eb9bbb6",
   "metadata": {},
   "source": [
    "\n",
    "When working with LLMs like Gemini, GPT-4, or Claude, everything starts with one fundamental building block:\n",
    "\n",
    "**The Prompt.**\n",
    "\n",
    "A prompt is simply how you talk to the model. It frames the task, provides instructions, gives context, and defines what response you're expecting.\n",
    "\n",
    "In everyday terms, think of a prompt like the question or instruction you'd give a human assistant:\n",
    "\n",
    "> \"Summarize this article in one paragraph.\"\n",
    "> \"Translate this sentence to French.\"\n",
    "> \"Write a polite email declining the meeting.\"\n",
    "\n",
    "The LLM can't read your mind — the prompt is how you steer its behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## Raw Prompts — Quick, but Messy\n",
    "\n",
    "You could always build prompts as plain strings:\n",
    "\n",
    "```python\n",
    "prompt = \"Translate the following sentence to French:\\n\\n'How are you today?'\"\n",
    "```\n",
    "\n",
    "But as your application grows, this becomes fragile:\n",
    "\n",
    "* You forget to escape characters\n",
    "* Prompts get long and unreadable\n",
    "* Reusing or customizing prompts is tedious\n",
    "* Debugging becomes frustrating\n",
    "\n",
    "Langchain fixes this with **Prompt Templates** and **Messages**, bringing clarity and control.\n",
    "\n",
    "---\n",
    "\n",
    "## Prompt Templates — Clean, Dynamic, Reusable\n",
    "\n",
    "Langchain provides **ChatPromptTemplate**, designed specifically for modern chat-based LLMs like Gemini.\n",
    "\n",
    "Here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc54a24-2657-4e9d-8250-75b270f77f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful French translator.\"),\n",
    "    (\"human\", \"Translate the following sentence to French:\\n{sentence}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4248f-581f-4298-b0e0-8552597df1c9",
   "metadata": {},
   "source": [
    "Notice the `{sentence}` placeholder? This lets you inject dynamic content later — perfect for real applications.\n",
    "\n",
    "When you're ready to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10785290-2e45-4b19-ac64-9d20b9b1925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt.format_messages(sentence=\"How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca93da-ecee-430b-b4bf-515f0c1a8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "`messages` now contains a properly structured list, ready for the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5042e39-7b2c-45a1-bd26-a96208237246",
   "metadata": {},
   "source": [
    "## Messages — Talking to the LLM Clearly\n",
    "\n",
    "Most modern LLMs (like Gemini) expect input in the form of **messages**, not just plain text. Messages mimic real conversations with different roles:\n",
    "\n",
    "* **System Message** — Sets behavior or background (\"You are a helpful assistant.\")\n",
    "* **Human Message** — Represents user input or questions\n",
    "* **AI Message** — Represents model responses (for history or multi-turn chats)\n",
    "\n",
    "Langchain models this perfectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4a291-6c51-40a5-90f5-8c7e0e0f3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import SystemMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What's the weather in Paris?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043aacb-8727-4a11-8d48-a70a2d5771d3",
   "metadata": {},
   "source": [
    "You can pass this to your LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a4b99-41d5-4462-a131-fd676ace84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950653b-7809-42be-982b-37f7a7f8ef17",
   "metadata": {},
   "source": [
    "\n",
    "This structure keeps conversations clean, organized, and closer to how chat-based LLMs naturally operate.\n",
    "\n",
    "---\n",
    "\n",
    "## Illustration — Why Messages Matter\n",
    "\n",
    "Imagine trying to build a chatbot that remembers context or follows instructions.\n",
    "\n",
    "With plain prompts:\n",
    "\n",
    "```python\n",
    "prompt = \"You are helpful.\\nUser: What's 2+2?\\nAssistant: 4\\nUser: What's 3+3?\"\n",
    "```\n",
    "\n",
    "Messy, hard to manage.\n",
    "\n",
    "With Langchain's messages:\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What's 2 + 2?\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"What's 3 + 3?\")\n",
    "]\n",
    "```\n",
    "\n",
    "Cleaner, explicit, and structured — no guesswork for you or the model.\n",
    "\n",
    "---\n",
    "\n",
    "## Prompt Templates + Messages = Best of Both Worlds\n",
    "\n",
    "You can combine both for maximum clarity and flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6652a81-8971-4e8c-8abd-2fad18586ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "messages = prompt.format_messages(question=\"Tell me a joke.\")\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938597b-963f-480f-8660-f26d3d075462",
   "metadata": {},
   "source": [
    "\n",
    "This approach:\n",
    "\n",
    "✅ Separates prompt logic from your app logic\n",
    "✅ Keeps prompts reusable and readable\n",
    "✅ Lets you inject dynamic values easily\n",
    "✅ Aligns perfectly with how LLM APIs expect inputs\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In real-world AI apps, how you structure prompts and messages directly affects:\n",
    "\n",
    "* Response quality\n",
    "* App reliability\n",
    "* Your sanity as a developer\n",
    "\n",
    "Langchain gives you:\n",
    "\n",
    "✔️ Prompt templates for clean, reusable instructions\n",
    "✔️ Message objects for organized, chat-like communication\n",
    "✔️ Flexibility to build AI features that scale\n",
    "\n",
    "---\n",
    "\n",
    "In the next part, we go beyond prompts — into the real orchestration:\n",
    "\n",
    "➡️ Chains — building multi-step AI logic\n",
    "➡️ LCEL — composing LLM workflows elegantly\n",
    "➡️ Runnables — modular, testable AI building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225aab92-0656-4e1f-81d6-7bff9f93ba61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
